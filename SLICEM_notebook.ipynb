{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sort 2D class averages using common lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import mrcfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import skimage as ski\n",
    "import itertools as it\n",
    "import multiprocessing \n",
    "from igraph import Graph\n",
    "from scipy import ndimage as ndi\n",
    "from scipy import spatial, signal, stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#choose metric for comparing 1D projections (Euclidean, L1, cross-correlation, cosine)\n",
    "metric = 'L1'\n",
    "\n",
    "#whether or not to zscore normalize 1D projections before scoring (not recommended)\n",
    "normalize = False\n",
    "\n",
    "#path to mrcs file of 2D class averages\n",
    "mrc_input = 'path/to/input/mixture_2D.mrcs\n",
    "\n",
    "#number of CPUs to use\n",
    "num_workers = 1\n",
    "\n",
    "#pixel size of 2D class averages in A/pixel\n",
    "pixel_size = 4\n",
    "\n",
    "#number of edges for each node in the graph\n",
    "neighbors = 5\n",
    "\n",
    "#community detection algorithm to use (betweenness, walktrap)\n",
    "community_detection = 'betweenness''\n",
    "\n",
    "#path for output files\n",
    "outpath = 'path/to/output/'\n",
    "\n",
    "#name for output file\n",
    "description = 'mixture'\n",
    "\n",
    "#path to star file for particles in 2D class averages\n",
    "star_input = 'path/to/matching/mixture_particles.star'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read in 2D projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Projection:\n",
    "    \"\"\"for 1D projection vectors\"\"\"\n",
    "    def __init__(self, \n",
    "                 class_avg,\n",
    "                 angle,\n",
    "                 vector): \n",
    "\n",
    "        self.class_avg = class_avg\n",
    "        self.angle = angle\n",
    "        self.vector = vector\n",
    "    \n",
    "    def size(self):\n",
    "        l = len(self.vector)\n",
    "        return(l)\n",
    "    \n",
    "    @property\n",
    "    def dimension(self):\n",
    "        return self.vector.ndim\n",
    "    \n",
    "def get_1D_projections(mrcs, norm):\n",
    "    \"\"\"\n",
    "    creates dictionary of 1D projections, key is [class avg number, projection angle] \n",
    "    \"\"\"\n",
    "    projection_2D = {}\n",
    "    \n",
    "    projection_1D = {}\n",
    "    \n",
    "    angles = np.arange(0, 360, 5)\n",
    "    \n",
    "    with mrcfile.open(mrc_input) as mrc:\n",
    "        for i, data in enumerate(mrc.data):\n",
    "            projection_2D[i] = data.astype('float64')\n",
    "            \n",
    "    for k, avg in projection_2D.items():\n",
    "        projection_2D[k] = extract_class_avg(avg)\n",
    "    \n",
    "    for k, avg in projection_2D.items():\n",
    "        for a in angles:\n",
    "            #to mimick original version, don't resize or trim avgs\n",
    "            proj_1D = ski.transform.rotate(avg, a, resize=True).sum(axis=0)\n",
    "            trim_1D = np.trim_zeros(proj_1D, trim='fb')\n",
    "            projection_1D[(k, a)] = Projection(class_avg = k,\n",
    "                                                   angle = a,\n",
    "                                                   vector = trim_1D)\n",
    "\n",
    "    if norm:\n",
    "        for k, v in projection_1D.items():\n",
    "            projection_1D[k].vector = stats.zscore(projection_1D[k].vector)\n",
    "    \n",
    "    return projection_2D, projection_1D  \n",
    "\n",
    "def extract_class_avg(avg):\n",
    "    \"\"\"\n",
    "    keep positive values from image normalization\n",
    "    remove extra densities in class average\n",
    "    fit in minimal bounding box\n",
    "    \"\"\"\n",
    "    #TODO: try different region extraction or masking\n",
    "    pos_img = avg\n",
    "    pos_img[pos_img < 0] = 0\n",
    "    \n",
    "    #dilate by pixel size to connect neighbor regions\n",
    "    extra = 3 #Angrstroms to dilate (set minimum of 3A)\n",
    "    extend = int(np.ceil((pixel_size/extra)**-1))\n",
    "\n",
    "    struct = np.ones((extend, extend), dtype=bool)\n",
    "    dilate = ndi.binary_dilation(input=pos_img, structure=struct)\n",
    "\n",
    "    labeled = ski.measure.label(dilate, connectivity=2, background=False)\n",
    "\n",
    "    #select a single region from each 2D class average\n",
    "    rprops = ski.measure.regionprops(labeled, cache=False)\n",
    "    bbox = [r.bbox for r in rprops]\n",
    "\n",
    "    if len(bbox) == 1:\n",
    "        #use only region in the image\n",
    "        selected = 1\n",
    "\n",
    "    elif len(bbox) > 1:\n",
    "        img_x_center = len(avg)/2\n",
    "        img_y_center = len(avg[:,0])/2\n",
    "        img_center = (img_x_center, img_y_center)\n",
    "        #for use in distance calculation\n",
    "        x1 = np.array(img_center)\n",
    "\n",
    "        box_range = {}\n",
    "        for i, box in enumerate(bbox):\n",
    "            width_coord = list(range(box[1], box[3]+1))\n",
    "            length_coord = list(range(box[0], box[2]+1))\n",
    "            box_range[i+1] = [width_coord, length_coord]\n",
    "\n",
    "        box_centers = {}\n",
    "        for i, box in enumerate(bbox):\n",
    "            y_max, y_min = box[0], box[2]\n",
    "            x_max, x_min = box[1], box[3]\n",
    "            center_xy = (((x_max+x_min)/2, (y_max+y_min)/2))\n",
    "            #i+1 because 0 is the background region\n",
    "            box_centers[i+1] = center_xy\n",
    "\n",
    "        selected = 'none'\n",
    "\n",
    "        for region, bound in box_range.items():\n",
    "            #first check if there is a region in the center\n",
    "            if img_x_center in bound[0] and img_y_center in bound[1]:\n",
    "                #use center region\n",
    "                selected = region\n",
    "\n",
    "        if selected == 'none':\n",
    "            #find box closest to the center    \n",
    "            distance = {}\n",
    "            for region, center in box_centers.items():\n",
    "                x2 = np.array(center)\n",
    "                distance[region] = spatial.distance.euclidean(x1, x2)  \n",
    "            region = min(distance, key=distance.get) \n",
    "            #use region closest to center\n",
    "            selected = region\n",
    "\n",
    "    selected_region = (labeled == selected)\n",
    "\n",
    "    properties = ski.measure.regionprops(selected_region.astype('int'))\n",
    "    bbox = properties[0].bbox\n",
    "\n",
    "    y_min, y_max = bbox[0], bbox[2]\n",
    "    x_min, x_max = bbox[1], bbox[3]\n",
    "\n",
    "    #keep only true pixels in bounding box\n",
    "    true_region = np.empty(avg.shape)\n",
    "\n",
    "    for i, row in enumerate(avg):\n",
    "        for j, pixel in enumerate(row):\n",
    "            if selected_region[(i,j)] == True:\n",
    "                true_region[(i,j)] = pos_img[(i, j)]\n",
    "            else:\n",
    "                true_region[(i,j)] = 0\n",
    "\n",
    "    new_region = true_region[y_min:y_max, x_min:x_max]\n",
    "\n",
    "    return new_region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "projection_2D, projection_1D = get_1D_projections(mrcs=mrc_input, norm=normalize)\n",
    "num_class_avg = len(projection_2D)\n",
    "\n",
    "n = len(projection_1D)\n",
    "print(\"number of 2D class averages: {}\".format(num_class_avg))\n",
    "print(\"number of 1D projection vectors: {}\".format(n))\n",
    "print(\"total number of pairwise scores: {}\".format(int(n*(n-1)/2)))\n",
    "\n",
    "#remove pairs from same 2D class average\n",
    "all_pairs = list(it.combinations(projection_1D.values(), 2))\n",
    "projection_pairs = [pair for pair in all_pairs if pair[0].class_avg != pair[1].class_avg]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sliding vector comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if metric == 'Euclidean':\n",
    "    def pairwise_score(a, b):\n",
    "        score = spatial.distance.euclidean(a.vector, b.vector)\n",
    "        return score\n",
    "        \n",
    "elif metric == 'L1':\n",
    "    def pairwise_score(a, b):\n",
    "        score = sum(abs(a.vector - b.vector))\n",
    "        return score\n",
    "    \n",
    "elif metric == 'cosine':\n",
    "    def pairwise_score(a, b):\n",
    "        score = spatial.distance.cosine(a.vector - b.vector)\n",
    "        return score   \n",
    "\n",
    "elif metric == 'cross-correlation':\n",
    "    def pairwise_score(a, b):\n",
    "        score = signal.correlate(a.vector, b.vector, mode='valid')\n",
    "        score_max = np.amax(score)\n",
    "        return score_max\n",
    "\n",
    "def slide_score(a, b):\n",
    "    \"\"\"\n",
    "    a, b are instances of the Projection class\n",
    "    finds minimum pairwise score for all translations\n",
    "    \"\"\"\n",
    "    lp1 = a.size()\n",
    "    lp2 = b.size()\n",
    "    \n",
    "    dol = abs(lp1 - lp2)\n",
    "    \n",
    "    if dol == 0:\n",
    "        score = pairwise_score(a, b)\n",
    "\n",
    "    else:\n",
    "        projection_shifts = []\n",
    "        \n",
    "        if lp1 > lp2:    \n",
    "            static = a\n",
    "            shift = b\n",
    "        else:\n",
    "            static = b\n",
    "            shift = a\n",
    "            \n",
    "        for i in range(0, dol+1):\n",
    "            v = np.pad(shift.vector, pad_width=(i, dol-i), mode='constant')\n",
    "            projection_shifts.append(Projection(class_avg = str(shift.class_avg)+'_'+str(i),\n",
    "                                                angle = shift.angle,\n",
    "                                                vector = v))\n",
    "\n",
    "        scores = []\n",
    "        \n",
    "        for shifted in projection_shifts:\n",
    "            scores.append(pairwise_score(static, shifted))\n",
    "        score = min(scores)\n",
    "        \n",
    "    return score\n",
    "\n",
    "def wrapper_function(pair, func):\n",
    "    \"\"\"\n",
    "    - pair is tuple of instances from Projection class\n",
    "    - func is how to pairwise score vectors defined from user\n",
    "    \"\"\"\n",
    "    score = func(pair[0], pair[1])\n",
    "    \n",
    "    return [pair[0].class_avg, \n",
    "            pair[0].angle, \n",
    "            pair[1].class_avg, \n",
    "            pair[1].angle,\n",
    "            score]\n",
    "\n",
    "def multiproc_pairwise():\n",
    "    with multiprocessing.Pool(num_workers) as pool:\n",
    "        if metric != 'cross-correlation':\n",
    "            pair_scores = pool.starmap(wrapper_function, \n",
    "                                       it.product(projection_pairs, [slide_score]))\n",
    "        else:\n",
    "            pair_scores = pool.starmap(wrapper_function, \n",
    "                                       it.product(projection_pairs, [pairwise_score]))\n",
    "    return pair_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    starttime = time.time()\n",
    "    scores = multiproc_pairwise()\n",
    "    print('That took: {} minutes'.format((time.time() - starttime)/60))\n",
    "    \n",
    "pairs = list(it.combinations(list(range(num_class_avg)), 2))\n",
    "\n",
    "score_matrix = {pair: [] for pair in pairs}\n",
    "\n",
    "for s in scores:\n",
    "    #format is [projection_1, projection_2] = [(angle_1, angle_2, score)]\n",
    "    score_matrix[s[0], s[2]].append((s[1], s[3], s[4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### find best pairwise scores between 2D classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def optimum_scores(score_matrix):\n",
    "    \"\"\"\n",
    "    best pairwise score for all 1D projections\n",
    "    \"\"\"\n",
    "    optimum_pairwise_scores = {}\n",
    "    \n",
    "    complete_score_matrix = {}\n",
    "\n",
    "    #cross-correlation optimum is max, other metrics are min\n",
    "    if metric != 'cross-correlation': \n",
    "        for pair, scores in score_matrix.items():\n",
    "            optimum_pairwise_scores[pair] = min(score_matrix[pair], key = lambda x: x[2])\n",
    "    else:\n",
    "        for pair, scores in score_matrix.items():\n",
    "            optimum_pairwise_scores[pair] = max(score_matrix[pair], key = lambda x: x[2])\n",
    "\n",
    "    #complete the matrix\n",
    "    for pair, value in optimum_pairwise_scores.items():\n",
    "        if pair[0] == pair[1]:\n",
    "            next\n",
    "        else:\n",
    "            complete_score_matrix[pair] = value\n",
    "            #now flip pair\n",
    "            score = value[2]\n",
    "            angle_1 = value[0]\n",
    "            angle_2 = value[1]\n",
    "            complete_score_matrix[(pair[1], pair[0])] = (angle_2, angle_1, score)\n",
    "        \n",
    "    return complete_score_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "complete_scores = optimum_scores(score_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nearest neighbors for each 2D class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nearest_neighbors(complete_scores):\n",
    "    \"\"\"\n",
    "    group k best scores for each class average to construct graph \n",
    "    \"\"\"\n",
    "    order_scores = {avg: [] for avg in range(num_class_avg)}\n",
    "    \n",
    "    projection_knn = {}\n",
    "\n",
    "    #reorganize score matrix to sort for nearest neighbors\n",
    "    #projection_knn[projection_1] = [projection_2, angle_1, angle_2, score]\n",
    "    for pair, values in complete_scores.items():\n",
    "        p1 = pair[0]\n",
    "        p2 = pair[1]\n",
    "        a1 = values[0]\n",
    "        a2 = values[1]\n",
    "        s = values[2]\n",
    "        \n",
    "        #option: convert distance to similarity\n",
    "        #if metric != 'cross-correlation':\n",
    "        #    s = 1/(1 + values[2])\n",
    "        #else:\n",
    "        #    s = values[2]\n",
    "            \n",
    "        c = [p2, a1, a2, s]\n",
    "        order_scores[p1].append(c)\n",
    "        \n",
    "    #zscore scores by each projection, use as edgeweight in graph\n",
    "    for projection, scores in order_scores.items():\n",
    "        all_scores = []\n",
    "        for v in scores:\n",
    "            all_scores.append(v[3])\n",
    "        \n",
    "        u = np.mean(all_scores)\n",
    "        s = np.std(all_scores)\n",
    "    \n",
    "        for v in scores:\n",
    "            zscore = (v[3] - u)/s\n",
    "            v[3] = zscore\n",
    "\n",
    "    for avg, scores in order_scores.items():\n",
    "        if metric != 'cross-correlation':\n",
    "            sort = sorted(scores, reverse=False, key=lambda x: x[3])[:neighbors]\n",
    "        else:\n",
    "            sort = sorted(scores, reverse=True, key=lambda x: x[3])[:neighbors]\n",
    "        projection_knn[avg] = sort\n",
    "                \n",
    "    return projection_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "projection_knn = nearest_neighbors(complete_scores=complete_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### use graph to cluster 2D classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def detect_communities(projection_knn):\n",
    "    \"\"\"\n",
    "    cluster graph using walktrap of edge betweeness\n",
    "    \"\"\"\n",
    "    flat = []\n",
    "    \n",
    "    clusters = {}\n",
    "\n",
    "    for projection, knn in projection_knn.items():\n",
    "        for n in knn:\n",
    "            #(proj_1, proj_2, score)\n",
    "            #abs score to correct for distance vs similarity\n",
    "            flat.append((projection, n[0], abs(n[3])))\n",
    "\n",
    "    g = Graph.TupleList(flat, weights=True)\n",
    "\n",
    "    if community_detection == 'walktrap':\n",
    "        wt = Graph.community_walktrap(g, weights='weight', steps=4)\n",
    "        cluster_dendrogram = wt.as_clustering()\n",
    "    elif community_detection == 'betweenness':\n",
    "        ebs = Graph.community_edge_betweenness(g, weights='weight', directed=True)\n",
    "        cluster_dendrogram = ebs.as_clustering()\n",
    "\n",
    "    for community, projection in enumerate(cluster_dendrogram.subgraphs()):\n",
    "        clusters[community] = projection.vs['name']\n",
    "\n",
    "    #convert node IDs back to ints\n",
    "    for cluster, nodes in clusters.items():\n",
    "        clusters[cluster] = [int(node) for node in nodes]\n",
    "        \n",
    "    return clusters\n",
    "\n",
    "\n",
    "def remove_outliers(clusters):\n",
    "    \"\"\"\n",
    "    use median absolute deviation of summed 2D projections to remove outliers\n",
    "    inspect outliers for further processing\n",
    "    \"\"\"\n",
    "    pixel_sums = {}\n",
    "    \n",
    "    outliers = []\n",
    "\n",
    "    for cluster, nodes in clusters.items():\n",
    "        pixel_sums[cluster] = []\n",
    "        for node in nodes:\n",
    "            pixel_sums[cluster].append(sum(sum(projection_2D[node])))\n",
    "\n",
    "    for cluster, psums in pixel_sums.items():\n",
    "        med = np.median(psums)\n",
    "        m_psums = [abs(x - med) for x in psums]\n",
    "        mad = np.median(m_psums)\n",
    "\n",
    "        for i, proj in enumerate(psums):\n",
    "            #Boris Iglewicz and David Hoaglin (1993)\n",
    "            z = 0.6745*(proj - med)/mad\n",
    "            if abs(z) > 3.5:\n",
    "                outliers.append((cluster, clusters[cluster][i]))\n",
    "\n",
    "    clusters[\"outliers\"] = [o[1] for o in outliers]\n",
    "    \n",
    "    for outlier in outliers:\n",
    "        cluster = outlier[0]\n",
    "        node = outlier[1]\n",
    "        clusters[cluster].remove(node)\n",
    "        print('projection node {0} was removed from cluster {1} as an outlier'.format(node, cluster))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clusters = detect_communities(projection_knn=projection_knn)\n",
    "\n",
    "remove_outliers(clusters=clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### write score outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_scores():\n",
    "    \"\"\"\n",
    "    tab separted text file of nearest neighbors \n",
    "    and complete score matrix\n",
    "    neighbors file can be input to cytoscape\n",
    "    \"\"\"\n",
    "    #tab separated: projection_1, angle_1, projection_2, angle_2, score    \n",
    "    with open(outpath+'/neighbors_{0}.txt'.format(description), 'w') as f:\n",
    "        f.write('projection_1' + '\\t' +'angle_1' + '\\t'\\\n",
    "                + 'projection_2' + '\\t' + 'angle_2' + '\\t' + 'edge_score' + '\\n')\n",
    "        for projection, neighbors in projection_knn.items():\n",
    "            for n in neighbors:\n",
    "                f.write(str(projection)+'\\t'+str(n[1])+'\\t'+str(n[0])+'\\t'+str(n[2])+'\\t'+str(n[3])+'\\n')\n",
    "\n",
    "    with open(outpath+'/complete_scores_{0}.txt'.format(description), 'w') as f:\n",
    "        f.write('projection_1' + '\\t' + 'angle_1' + '\\t' +'projection_2' +\\\n",
    "                '\\t' + 'angle_2' + '\\t' + 'score' + '\\n')\n",
    "        for p, v in complete_scores.items():\n",
    "            f.write(str(p[0])+'\\t'+str(v[0])+'\\t'+str(p[1])+'\\t'+str(v[1])+'\\t'+str(v[2])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_scores()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split star file by clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "functions to parse star file adapted from Tristan Bepler\n",
    "https://github.com/tbepler/topaz\n",
    "https://www.nature.com/articles/s41592-019-0575-8\n",
    "\"\"\"\n",
    "\n",
    "def parse_star(f):\n",
    "    return parse(f)\n",
    "\n",
    "def parse(f):\n",
    "    lines = f.readlines()\n",
    "    for i in range(len(lines)):\n",
    "        line = lines[i]\n",
    "        if line.startswith('data_'): \n",
    "            return parse_star_body(lines[i+1:])\n",
    "        \n",
    "def parse_star_body(lines):\n",
    "    #data_images line has been read, next is loop\n",
    "    for i in range(len(lines)):\n",
    "        if lines[i].startswith('loop_'):\n",
    "            lines = lines[i+1:]\n",
    "            break\n",
    "    header,lines = parse_star_loop(lines)\n",
    "    #parse the body\n",
    "    content = []\n",
    "    for i in range(len(lines)):\n",
    "        line = lines[i].strip()\n",
    "        if line.startswith('data'): # done with image block\n",
    "            break\n",
    "        if line.startswith('#') or line.startswith(';'): # comment lines\n",
    "            continue\n",
    "        if line != '':\n",
    "            tokens = line.split()\n",
    "            content.append(tokens)\n",
    "            \n",
    "    table = pd.DataFrame(content, columns=header)\n",
    "    \n",
    "    return table      \n",
    "    \n",
    "def parse_star_loop(lines):\n",
    "    columns = []\n",
    "    for i in range(len(lines)):\n",
    "        line = lines[i].strip()\n",
    "        if not line.startswith('_'):\n",
    "            break\n",
    "        name = line[1:]\n",
    "        #strip trailing comments from name\n",
    "        loc = name.find('#')\n",
    "        if loc >= 0:\n",
    "            name = name[:loc]\n",
    "        #strip 'rln' prefix\n",
    "        if name.startswith('rln'):\n",
    "            name = name[3:]\n",
    "        name = name.strip()\n",
    "        \n",
    "        columns.append(name)\n",
    "        \n",
    "    return columns, lines[i:]\n",
    "\n",
    "def write_star_files():\n",
    "    \"\"\"\n",
    "    split star file into new star files based on clusters\n",
    "    \"\"\"\n",
    "    with open(star_input, 'r') as f:\n",
    "        table = parse_star(f)\n",
    "\n",
    "    cluster_star = {}\n",
    "\n",
    "    for cluster, nodes in clusters.items():\n",
    "        #convert to str to match df\n",
    "        #add 1 to match RELION indexing\n",
    "        avgs = [str(node+1) for node in nodes]\n",
    "        subset = table[table['ClassNumber'].isin(avgs)]\n",
    "        cluster_star[cluster] = subset\n",
    "\n",
    "    for cluster, table in cluster_star.items():\n",
    "        with open(outpath+'/{0}_cluster_{1}.star'.format(description, cluster), 'w') as f:\n",
    "            #write the star file\n",
    "            print('data_', file=f)\n",
    "            print('loop_', file=f)\n",
    "            for i, name in enumerate(table.columns):\n",
    "                print('_rln' + name + ' #' + str(i+1), file=f)\n",
    "            table.to_csv(f, sep='\\t', index=False, header=False)\n",
    "            \n",
    "    with open(outpath+'/{0}_clusters.txt'.format(description), 'w') as f:\n",
    "        for cluster, averages in clusters.items():\n",
    "            f.write(str(cluster) + '\\t' + str(averages) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_star_files()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
