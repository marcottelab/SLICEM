{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sort 2D projections by common lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import mrcfile\n",
    "import itertools\n",
    "import numpy as np\n",
    "from igraph import Graph\n",
    "from scipy import ndimage as ndi\n",
    "from skimage import transform, measure\n",
    "from scipy import signal, spatial, stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Path to mrcs file of 2D class averages\n",
    "mrc_input = 'path/to/input/mixture_2D.mrcs'\n",
    "\n",
    "#Path to star file for particles in 2D class averages\n",
    "star_input = 'path/to/matching/mixture_particles.star'\n",
    "\n",
    "#Path for output files\n",
    "outpath = 'path/to/output/'\n",
    "\n",
    "#Name for output file\n",
    "description = 'mixture'\n",
    "\n",
    "#Pixel size of 2D class averages in A/pixel\n",
    "pixel_size = 4\n",
    "\n",
    "#Choose metric for comparing 1D projections (NCC, cross-correlation, Euclidean, Norm-Euc, cosine, difference)\n",
    "metric = 'Euclidean'\n",
    "\n",
    "#Number of edges for each node in the graph\n",
    "neighbors = 5\n",
    "\n",
    "#Community detection algorithm to use (betweenness, walktrap)\n",
    "community_detection = 'betweenness'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Set up angles for 2D->1D projections\n",
    "interval = 5\n",
    "angle = 360\n",
    "\n",
    "#metrics to add 'sliding' feature too, analogous to cross-correlation\n",
    "slide = ['Euclidean', 'Norm-Euc', 'cosine', 'difference']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read in 2D projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "projection2d = {}\n",
    "\n",
    "with mrcfile.open(mrc_input) as mrc:\n",
    "    for i, data in enumerate(mrc.data):\n",
    "        projection2d[i] = data.astype('float64')\n",
    "        \n",
    "#2D projections are named numerically to match mrcs file\n",
    "file_names = list(range(len(projection2d)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### extract class averages from background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#If using synthetic reprojections from EMAN, skip this block\n",
    "\n",
    "for name, image in projection2d.items():\n",
    "    #keep pixel values greater than the zero-mean, set everything else to zero\n",
    "    #TODO: test different region extraction algorithms\n",
    "    img_thresh = np.empty(image.shape)\n",
    "    for i, row in enumerate(image):\n",
    "        for j, pixel in enumerate(row):\n",
    "            if image[(i,j)] < 0:\n",
    "                img_thresh[(i,j)] = 0\n",
    "            else:\n",
    "                img_thresh[(i, j)] = image[(i,j)]\n",
    "    \n",
    "    #dilate by pixel size to connect neighbor regions\n",
    "    extra = 3 #Angrstroms to dilate (set minimum of 3A)\n",
    "    extend = int(np.ceil((pixel_size/extra)**-1))\n",
    "\n",
    "    struct = np.ones((extend, extend), dtype=bool)\n",
    "    dilate = ndi.binary_dilation(input=img_thresh, structure=struct)\n",
    "\n",
    "    labeled = measure.label(dilate, connectivity=2, background=False)\n",
    "\n",
    "    #select a single region from each 2D class average\n",
    "    rprops = measure.regionprops(labeled, cache=False)\n",
    "    bbox = [r.bbox for r in rprops]\n",
    "\n",
    "    if len(bbox) == 1:\n",
    "        #use only region in the image\n",
    "        selected = 1\n",
    "\n",
    "    elif len(bbox) > 1:\n",
    "        img_x_center = len(image)/2\n",
    "        img_y_center = len(image[:,0])/2\n",
    "        img_center = (img_x_center, img_y_center)\n",
    "        #for use in distance calculation\n",
    "        x1 = np.array(img_center)\n",
    "\n",
    "        box_range = {}\n",
    "        for i, box in enumerate(bbox):\n",
    "            width_coord = list(range(box[1], box[3]+1))\n",
    "            length_coord = list(range(box[0], box[2]+1))\n",
    "            box_range[i+1] = [width_coord, length_coord]\n",
    "\n",
    "        box_centers = {}\n",
    "        for i, box in enumerate(bbox):\n",
    "            y_max, y_min = box[0], box[2]\n",
    "            x_max, x_min = box[1], box[3]\n",
    "            center_xy = (((x_max+x_min)/2, (y_max+y_min)/2))\n",
    "            #i+1 because 0 is the background region\n",
    "            box_centers[i+1] = center_xy\n",
    "\n",
    "        selected = 'none'\n",
    "\n",
    "        for region, bound in box_range.items():\n",
    "            #first check if there is a region in the center\n",
    "            if img_x_center in bound[0] and img_y_center in bound[1]:\n",
    "                #use center region\n",
    "                selected = region\n",
    "\n",
    "        if selected == 'none':\n",
    "            #find box closest to the center    \n",
    "            distance = {}\n",
    "            for region, center in box_centers.items():\n",
    "                x2 = np.array(center)\n",
    "                distance[region] = spatial.distance.euclidean(x1, x2)  \n",
    "            region = min(distance, key=distance.get) \n",
    "            #use region closest to center\n",
    "            selected = region\n",
    "\n",
    "    selected_region = (labeled == selected)\n",
    "\n",
    "    properties = measure.regionprops(selected_region.astype('int'))\n",
    "    bbox = properties[0].bbox\n",
    "\n",
    "    y_min, y_max = bbox[0], bbox[2]\n",
    "    x_min, x_max = bbox[1], bbox[3]\n",
    "    \n",
    "    #keep only true pixels in bounding box\n",
    "    true_region = np.empty(image.shape)\n",
    "    \n",
    "    for i, row in enumerate(image):\n",
    "        for j, pixel in enumerate(row):\n",
    "            if selected_region[(i,j)] == True:\n",
    "                true_region[(i,j)] = image[(i, j)]\n",
    "            else:\n",
    "                true_region[(i,j)] = 0\n",
    "                \n",
    "    new_region = true_region[y_min:y_max, x_min:x_max]\n",
    "    \n",
    "    projection2d[name] = new_region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create 1d projection vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_projections = len(projection2d)\n",
    "print('\\n'+'calculting line scores for {0} pairs of projections'\\\n",
    "      .format(int((n_projections**2)/2 + (n_projections/2))))\n",
    "\n",
    "#Keep projections as a list to slice later\n",
    "projection_1D = []\n",
    "\n",
    "rot_angles = np.arange(0, angle+1, interval)\n",
    "\n",
    "#Rotate and project to 1D on x-axis, effectively creates a sinogram\n",
    "for key, projection in projection2d.items():\n",
    "    for angle in rot_angles:\n",
    "        proj_1D = transform.rotate(projection, angle).sum(axis=0)\n",
    "        if metric == 'NCC' or metric == 'norm-Euc':\n",
    "            norm_proj_1D = stats.zscore(proj_1D) \n",
    "            projection_1D.append([(key, angle), norm_proj_1D])\n",
    "        else:\n",
    "            projection_1D.append([(key, angle), proj_1D])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sliding vector comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score_matrix = {}\n",
    "\n",
    "#Calculate sliding vector scores to account for translations in 1D projections\n",
    "if metric in slide:\n",
    "    for i, proj_1 in enumerate(projection_1D):\n",
    "        lp1 = len(proj_1[1])\n",
    "        #slice to calculate upper triangular matrix\n",
    "        for proj_2 in projection_1D[i:]:\n",
    "            lp2 = len(proj_2[1])\n",
    "            dol = abs(lp1 - lp2)\n",
    "            proj_shift = []\n",
    "\n",
    "            if dol == 0:\n",
    "                if metric == 'difference':\n",
    "                    score = sum(abs(proj_1[1] - proj_2[1]))\n",
    "                elif metric == 'Euclidean' or metric == 'Norm-Euc':\n",
    "                    score = spatial.distance.euclidean(proj_1[1], proj_2[1])\n",
    "                elif metric == 'cosine':\n",
    "                    score = spatial.distance.cosine(proj_1[1], proj_2[1])\n",
    "\n",
    "            #store position and score of minimum \n",
    "            elif lp1 < lp2:\n",
    "                static = proj_2[1]\n",
    "                for i in range(0, dol+1):\n",
    "                    proj_shift.append(np.pad(proj_1[1], pad_width=(i, dol-i), mode='constant'))\n",
    "            elif lp1 > lp2:\n",
    "                static = proj_1[1]\n",
    "                for i in range(0, dol+1):\n",
    "                    proj_shift.append(np.pad(proj_2[1], pad_width=(i, dol-i), mode='constant'))\n",
    "            else:\n",
    "                print('something is wrong with the 1D projections')\n",
    "\n",
    "            if dol != 0:\n",
    "                scores = []\n",
    "                for shift in proj_shift:\n",
    "                    if metric == 'difference':\n",
    "                        val = sum(abs(static - shift))\n",
    "                    elif metric == 'Euclidean' or metric == 'Norm-Euc':\n",
    "                        val = spatial.distance.euclidean(static, shift)\n",
    "                    elif metric == 'cosine':\n",
    "                        val = spatial.distance.cosine(static, shift)\n",
    "                    scores.append(val)\n",
    "                #metrics in 'slide' are dissimilarity, smaller values are better\n",
    "                score = min(scores)\n",
    "            #format for score_matrix [proj_1, angle_1, proj_2, angle_2] = score\n",
    "            score_matrix[proj_1[0][0], proj_1[0][1], proj_2[0][0], proj_2[0][1]] = score\n",
    "            \n",
    "elif metric == 'cross-correlation' or metric == 'NCC':\n",
    "    for i, proj_1 in enumerate(projection_1D):\n",
    "        for proj_2 in projection_1D[i:]:\n",
    "            score = signal.correlate(proj_1[1], proj_2[1], mode='valid')\n",
    "            score_matrix[proj_1[0][0], proj_1[0][1], proj_2[0][0], proj_2[0][1]] = score          \n",
    "    for key, array in score_matrix.items():\n",
    "        score_matrix[key] = np.amax(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#optional output of all scores (this is a large text file! 100 projections --> 2.6*10^7 lines)\n",
    "\n",
    "#with open(outpath+'/{0}_raw_scores.txt'.format(description), 'w') as f:\n",
    "#    f.write('projection_1' + '\\t' + 'angle_1' + '\\t' +'projection_2' + '\\t' + 'angle_2' + '\\t' + 'score' + '\\n')\n",
    "#    for key, value in score_matrix.items():\n",
    "#        f.write(str(key[0]) +'\\t'+ str(key[1]) +'\\t'+ str(key[2]) +'\\t'+ str(key[3]) +'\\t'+ '%f'%(value) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  final common line scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get the optimum score for each pair of projection images \n",
    "\n",
    "final_scores = {}\n",
    "complete_score_matrix = {}\n",
    "\n",
    "#Generate pairs for the number of 2D projections\n",
    "pairs = list(itertools.combinations_with_replacement(file_names, 2))\n",
    "\n",
    "#Initialize final score (proj1, proj2) = [score, angle_proj1, angle_proj2]\n",
    "final_scores = {pair: [score_matrix[pair[0], 0, pair[1], 0], 0, 0] for pair in pairs}\n",
    "\n",
    "if metric in slide: \n",
    "    for key, value in score_matrix.items():\n",
    "        if value < final_scores[(key[0], key[2])][0]:\n",
    "            final_scores[(key[0], key[2])][0] = value\n",
    "            final_scores[(key[0], key[2])][1] = key[1]\n",
    "            final_scores[(key[0], key[2])][2] = key[3]\n",
    "\n",
    "elif metric == 'cross-correlation' or metric == 'NCC':\n",
    "    for key, value in score_matrix.items():\n",
    "        if value > final_scores[(key[0], key[2])][0]:\n",
    "            final_scores[(key[0], key[2])][0] = value\n",
    "            final_scores[(key[0], key[2])][1] = key[1]\n",
    "            final_scores[(key[0], key[2])][2] = key[3]\n",
    "            \n",
    "for key, value in final_scores.items():\n",
    "    complete_score_matrix[key] = value\n",
    "    score = value[0]\n",
    "    angle_1 = value[1]\n",
    "    angle_2 = value[2]\n",
    "    complete_score_matrix[(key[1], key[0])] = [score, angle_2, angle_1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "proj_scores = {}\n",
    "\n",
    "for i in range(len(projection2d)):\n",
    "    proj_scores[i] = []\n",
    "    for j in range(len(projection2d)):\n",
    "        proj_scores[i].append(complete_score_matrix[(i, j)][0])\n",
    "        \n",
    "    #TODO: apply different edgeweighting strategies\n",
    "    zscores = stats.zscore(proj_scores[i])\n",
    "    proj_scores[i] = zscores\n",
    "    \n",
    "proj_knn = {key: [] for key in range(len(projection2d))}\n",
    "\n",
    "for projection, scores in proj_scores.items():\n",
    "    sort_scores = sorted((score, i) for i, score in enumerate(proj_scores[projection]))\n",
    "    if metric not in slide:\n",
    "        sort_scores = sorted(sort_scores, reverse=True)\n",
    "    count = 0\n",
    "    for zscore in sort_scores:\n",
    "        if count < neighbors and zscore[1] != projection:\n",
    "            #proj_knn format is (proj_1) = [[score, (proj_1, angle_1, proj_2, angle_2)]]\n",
    "            proj_knn[projection].append([abs(zscore[0]),\\\n",
    "                                        (projection,\\\n",
    "                                         complete_score_matrix[(projection, zscore[1])][1],\\\n",
    "                                         zscore[1],\\\n",
    "                                         complete_score_matrix[(projection, zscore[1])][2])])\n",
    "            count = count + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cluster 2d projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flat = []\n",
    "\n",
    "for proj, neighbors in proj_knn.items():\n",
    "    for n in neighbors:\n",
    "        #(proj_1, proj_2, score)\n",
    "        flat.append((str(proj), str(n[1][2]), n[0]))\n",
    "\n",
    "g = Graph.TupleList(flat, weights=True)\n",
    "\n",
    "if community_detection == 'walktrap':\n",
    "    wt = Graph.community_walktrap(g, weights='weight', steps=4)\n",
    "    cluster_dendrogram = wt.as_clustering()\n",
    "elif community_detection == 'betweenness':\n",
    "    ebs = Graph.community_edge_betweenness(g, weights='weight', directed=True)\n",
    "    cluster_dendrogram = ebs.as_clustering()\n",
    "\n",
    "clusters = {}\n",
    "for comm, proj in enumerate(cluster_dendrogram.subgraphs()):\n",
    "    clusters[comm] = proj.vs['name']\n",
    "\n",
    "#Convert vertex IDs back to int\n",
    "for key, comm in clusters.items():\n",
    "    clusters[key] = [int(proj) for proj in comm]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remove outliers from clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Use median absolute deviation of summed 2D projections to remove outliers\n",
    "#Evaluate outliers for further processing\n",
    "\n",
    "pixel_sums = {}\n",
    "\n",
    "for cluster, nodes in clusters.items():\n",
    "    pixel_sums[cluster] = []\n",
    "    for node in nodes:\n",
    "        pixel_sums[cluster].append(sum(sum(projection2d[node])))\n",
    "\n",
    "for cluster, psums in pixel_sums.items():\n",
    "    med = np.median(psums)\n",
    "    m_psums = [abs(x - m1) for x in psums]\n",
    "    mad = np.median(m_psums)\n",
    "    \n",
    "    for i, proj in enumerate(psums):\n",
    "        #Boris Iglewicz and David Hoaglin (1993)\n",
    "        z = 0.6745*(proj - med)/mad\n",
    "        if abs(z) > 3.5:\n",
    "            print('projection node {0} was removed from cluster {1} as an outlier'\\\n",
    "                  .format(clusters[cluster][i], cluster))\n",
    "            clusters[cluster].pop(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### score output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Complete score matrix output\n",
    "#Output is tab separated: projection_1, angle_1, projection_2, angle_2, score\n",
    "with open(outpath+'/complete_scores_{0}.txt'.format(description), 'w') as f:\n",
    "    f.write('projection_1' + '\\t' + 'angle_1' + '\\t' +'projection_2' +\\\n",
    "            '\\t' + 'angle_2' + '\\t' + 'score' + '\\n')\n",
    "    for key, value in complete_score_matrix.items():\n",
    "        f.write(str(key[0]) +'\\t'+ str(value[1]) +'\\t'+ str(key[1]) +'\\t'+\\\n",
    "                str(value[2]) +'\\t'+ '%f'%(value[0]) + '\\n')\n",
    "        \n",
    "#Nearest neighbors output\n",
    "#Output is tab separated: projection_1, angle_1, projection_2, angle_2, score    \n",
    "with open(outpath+'/neighbors_{0}.txt'.format(description), 'w') as f:\n",
    "    f.write('projection_1' + '\\t' +'angle_1' + '\\t'\\\n",
    "            + 'projection_2' + '\\t' + 'angle_2' + '\\t' + 'edge_score' + '\\n')\n",
    "    for key, value in proj_knn.items():\n",
    "        for item in value:\n",
    "            f.write(str(key) + '\\t' + str(item[1][1]) + '\\t'\\\n",
    "                    + str(item[1][2]) + '\\t' + str(item[1][3]) + '\\t' + str(item[0]) + '\\n')        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### output cluster star files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h_count = 0\n",
    "header = []\n",
    "class_average = {}\n",
    "\n",
    "with open(star_input) as f:\n",
    "    for raw_line in f:\n",
    "        line = raw_line.rstrip('\\n').split()\n",
    "        h_count = h_count + 1\n",
    "        if h_count < 33:\n",
    "            header.append(line)\n",
    "        else:\n",
    "            #skip blank lines\n",
    "            if len(line) > 10:\n",
    "                #line[23]-1 because relion index starts at 1, mrc and clusters start at 0\n",
    "                if int(line[23])-1 in class_average:\n",
    "                    class_average[int(line[23])-1].append(line)\n",
    "                else:\n",
    "                    class_average[int(line[23])-1] = [line]\n",
    "\n",
    "#Format header for output\n",
    "for i, entry in enumerate(header):\n",
    "    if i == 1:\n",
    "        header[i] = ['\\n'+str(header[i][0])+'\\n']\n",
    "    if len(entry) > 1:\n",
    "        header[i] = [' '.join(entry)]\n",
    "        \n",
    "flat_header = [entry for sub in header for entry in sub]\n",
    "\n",
    "output = {cluster: [] for cluster, proj in clusters.items()}\n",
    "\n",
    "for cluster, averages in clusters.items():\n",
    "    for average in averages:\n",
    "        output[cluster].append(class_average[average])\n",
    "\n",
    "for cluster, data in output.items():\n",
    "    with open(outpath+'/{0}_cluster_{1}.star'.format(description, cluster), 'w') as f:\n",
    "        f.write('\\n'.join(flat_header)+'\\n')\n",
    "        for particle_list in data:\n",
    "            for particles in particle_list:\n",
    "                f.write('\\t'.join(particles)+'\\n')\n",
    "                \n",
    "with open(outpath+'/{0}_clusters.txt'.format(description), 'w') as f:\n",
    "    for cluster, averages in clusters.items():\n",
    "        f.write(str(cluster) + '\\t' + str(averages) + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
